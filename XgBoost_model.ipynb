{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import operator\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\") #Needed to save figures\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    for i, feat in enumerate(features):\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "    outfile.close()\n",
    "\n",
    "def rmspe(y, yhat):\n",
    "    return np.sqrt(np.mean((yhat/y-1) ** 2))\n",
    "\n",
    "def rmspe_xg(yhat, y):\n",
    "    y = np.expm1(y.get_label())\n",
    "    yhat = np.expm1(yhat)\n",
    "    return \"rmspe\", rmspe(y,yhat)\n",
    "\n",
    "# Gather some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(features, data):\n",
    "    # remove NaNs\n",
    "    data.fillna(0, inplace=True)\n",
    "    data.loc[data.Open.isnull(), 'Open'] = 1\n",
    "    # Use some properties directly\n",
    "    features.extend(['Store', 'CompetitionDistance', 'Promo', 'SchoolHoliday'])\n",
    "\n",
    "    # Label encode some features\n",
    "    features.extend(['StoreType', 'Assortment', 'StateHoliday'])\n",
    "    mappings = {'0':0, 'a':1, 'b':2, 'c':3, 'd':4}\n",
    "    data.StoreType.replace(mappings, inplace=True)\n",
    "    data.Assortment.replace(mappings, inplace=True)\n",
    "    data.StateHoliday.replace(mappings, inplace=True)\n",
    "\n",
    "    features.extend(['DayOfWeek', 'Month', 'Day', 'Year', 'WeekOfYear'])\n",
    "    data['Year'] = data.Date.dt.year\n",
    "    data['Month'] = data.Date.dt.month\n",
    "    data['Day'] = data.Date.dt.day\n",
    "    data['DayOfWeek'] = data.Date.dt.dayofweek\n",
    "    data['WeekOfYear'] = data.Date.dt.weekofyear\n",
    "    \n",
    "    \n",
    "    features.append('CompetitionOpen')\n",
    "    data['CompetitionOpen'] = 12 * (data.Year - data.CompetitionOpenSinceYear) + \\\n",
    "        (data.Month - data.CompetitionOpenSinceMonth)\n",
    "    # Promo open time in months\n",
    "    features.append('PromoOpen')\n",
    "    data['PromoOpen'] = 12 * (data.Year - data.Promo2SinceYear) + \\\n",
    "        (data.WeekOfYear - data.Promo2SinceWeek) / 4.0\n",
    "    data['PromoOpen'] = data.PromoOpen.apply(lambda x: x if x > 0 else 0)\n",
    "    data.loc[data.Promo2SinceYear == 0, 'PromoOpen'] = 0\n",
    "\n",
    "    # Indicate that sales on that day are in promo interval\n",
    "    features.append('IsPromoMonth')\n",
    "    month2str = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', \\\n",
    "             7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
    "    data['monthStr'] = data.Month.map(month2str)\n",
    "    data.loc[data.PromoInterval == 0, 'PromoInterval'] = ''\n",
    "    data['IsPromoMonth'] = 0\n",
    "    for interval in data.PromoInterval.unique():\n",
    "        if interval != '':\n",
    "            for month in interval.split(','):\n",
    "                data.loc[(data.monthStr == month) & (data.PromoInterval == interval), 'IsPromoMonth'] = 1\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the training, test and store data using pandas\n"
     ]
    }
   ],
   "source": [
    "print(\"Load the training, test and store data using pandas\")\n",
    "types = {'CompetitionOpenSinceYear': np.dtype(int),\n",
    "         'CompetitionOpenSinceMonth': np.dtype(int),\n",
    "         'StateHoliday': np.dtype(str),\n",
    "         'Promo2SinceWeek': np.dtype(int),\n",
    "         'SchoolHoliday': np.dtype(float),\n",
    "         'PromoInterval': np.dtype(str)}\n",
    "train = pd.read_csv(\"train.csv\", parse_dates=[2], dtype=types)\n",
    "test = pd.read_csv(\"test.csv\", parse_dates=[3], dtype=types)\n",
    "store = pd.read_csv(\"store.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assume store open, if not provided\n",
      "Consider only open stores for training. Closed stores wont count into the score.\n",
      "Use only Sales bigger then zero. Simplifies calculation of rmspe\n",
      "Join with store\n",
      "augment features\n",
      "['Store', 'CompetitionDistance', 'Promo', 'SchoolHoliday', 'StoreType', 'Assortment', 'StateHoliday', 'DayOfWeek', 'Month', 'Day', 'Year', 'WeekOfYear', 'CompetitionOpen', 'PromoOpen', 'IsPromoMonth']\n"
     ]
    }
   ],
   "source": [
    "print(\"Assume store open, if not provided\")\n",
    "train.fillna(1, inplace=True)\n",
    "test.fillna(1, inplace=True)\n",
    "\n",
    "print(\"Consider only open stores for training. Closed stores wont count into the score.\")\n",
    "train = train[train[\"Open\"] != 0]\n",
    "print(\"Use only Sales bigger then zero. Simplifies calculation of rmspe\")\n",
    "train = train[train[\"Sales\"] > 0]\n",
    "\n",
    "print(\"Join with store\")\n",
    "train = pd.merge(train, store, on='Store')\n",
    "test = pd.merge(test, store, on='Store')\n",
    "\n",
    "features = []\n",
    "\n",
    "print(\"augment features\")\n",
    "build_features(features, train)\n",
    "build_features([], test)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data processed\n"
     ]
    }
   ],
   "source": [
    "print('training data processed')\n",
    "\n",
    "params = {\"objective\": \"reg:linear\",\n",
    "          \"booster\" : \"gbtree\",\n",
    "          \"eta\": 0.3,\n",
    "          \"max_depth\": 10,\n",
    "          \"subsample\": 0.9,\n",
    "          \"colsample_bytree\": 0.7,\n",
    "          \"silent\": 1,\n",
    "          \"seed\": 1301\n",
    "          }\n",
    "num_boost_round = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train a XGBoost model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anacondasoftware\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:5.79355\teval-rmse:5.79446\ttrain-rmspe:0.996844\teval-rmspe:0.996845\n",
      "Multiple eval metrics have been passed: 'eval-rmspe' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmspe hasn't improved in 100 rounds.\n",
      "[1]\ttrain-rmse:4.0633\teval-rmse:4.06536\ttrain-rmspe:0.981474\teval-rmspe:0.981497\n",
      "[2]\ttrain-rmse:2.8537\teval-rmse:2.85559\ttrain-rmspe:0.937983\teval-rmspe:0.938041\n",
      "[3]\ttrain-rmse:2.01024\teval-rmse:2.01223\ttrain-rmspe:0.856537\teval-rmspe:0.856573\n",
      "[4]\ttrain-rmse:1.42318\teval-rmse:1.42518\ttrain-rmspe:0.74412\teval-rmspe:0.743763\n",
      "[5]\ttrain-rmse:1.01854\teval-rmse:1.02021\ttrain-rmspe:0.619784\teval-rmspe:0.617985\n",
      "[6]\ttrain-rmse:0.742679\teval-rmse:0.744681\ttrain-rmspe:0.505335\teval-rmspe:0.501458\n",
      "[7]\ttrain-rmse:0.557015\teval-rmse:0.55916\ttrain-rmspe:0.415209\teval-rmspe:0.407433\n",
      "[8]\ttrain-rmse:0.436924\teval-rmse:0.439315\ttrain-rmspe:0.354322\teval-rmspe:0.342618\n",
      "[9]\ttrain-rmse:0.354692\teval-rmse:0.357384\ttrain-rmspe:0.316391\teval-rmspe:0.300593\n",
      "[10]\ttrain-rmse:0.310754\teval-rmse:0.313398\ttrain-rmspe:0.302155\teval-rmspe:0.282891\n",
      "[11]\ttrain-rmse:0.283793\teval-rmse:0.286664\ttrain-rmspe:0.297013\teval-rmspe:0.274916\n",
      "[12]\ttrain-rmse:0.269194\teval-rmse:0.272052\ttrain-rmspe:0.297436\teval-rmspe:0.272842\n",
      "[13]\ttrain-rmse:0.256105\teval-rmse:0.258728\ttrain-rmspe:0.294227\teval-rmspe:0.268228\n",
      "[14]\ttrain-rmse:0.246976\teval-rmse:0.249718\ttrain-rmspe:0.292392\teval-rmspe:0.265612\n",
      "[15]\ttrain-rmse:0.239578\teval-rmse:0.241249\ttrain-rmspe:0.289602\teval-rmspe:0.261142\n",
      "[16]\ttrain-rmse:0.234982\teval-rmse:0.236682\ttrain-rmspe:0.288187\teval-rmspe:0.259856\n",
      "[17]\ttrain-rmse:0.227035\teval-rmse:0.228365\ttrain-rmspe:0.282402\teval-rmspe:0.252956\n",
      "[18]\ttrain-rmse:0.225498\teval-rmse:0.227277\ttrain-rmspe:0.282351\teval-rmspe:0.25321\n",
      "[19]\ttrain-rmse:0.223226\teval-rmse:0.225018\ttrain-rmspe:0.281102\teval-rmspe:0.252044\n",
      "[20]\ttrain-rmse:0.214053\teval-rmse:0.215549\ttrain-rmspe:0.271742\teval-rmspe:0.24117\n",
      "[21]\ttrain-rmse:0.2127\teval-rmse:0.214402\ttrain-rmspe:0.270829\teval-rmspe:0.240374\n",
      "[22]\ttrain-rmse:0.204659\teval-rmse:0.206678\ttrain-rmspe:0.262803\teval-rmspe:0.232128\n",
      "[23]\ttrain-rmse:0.198919\teval-rmse:0.200811\ttrain-rmspe:0.258019\teval-rmspe:0.22537\n",
      "[24]\ttrain-rmse:0.194177\teval-rmse:0.196254\ttrain-rmspe:0.253707\teval-rmspe:0.220577\n",
      "[25]\ttrain-rmse:0.190972\teval-rmse:0.193213\ttrain-rmspe:0.250938\teval-rmspe:0.217644\n",
      "[26]\ttrain-rmse:0.187315\teval-rmse:0.189987\ttrain-rmspe:0.24633\teval-rmspe:0.213786\n",
      "[27]\ttrain-rmse:0.185425\teval-rmse:0.188095\ttrain-rmspe:0.244734\teval-rmspe:0.211883\n",
      "[28]\ttrain-rmse:0.181172\teval-rmse:0.183773\ttrain-rmspe:0.24064\teval-rmspe:0.20747\n",
      "[29]\ttrain-rmse:0.179581\teval-rmse:0.182246\ttrain-rmspe:0.239547\teval-rmspe:0.205993\n",
      "[30]\ttrain-rmse:0.175975\teval-rmse:0.17852\ttrain-rmspe:0.236278\teval-rmspe:0.20279\n",
      "[31]\ttrain-rmse:0.174353\teval-rmse:0.176912\ttrain-rmspe:0.234963\teval-rmspe:0.200972\n",
      "[32]\ttrain-rmse:0.172982\teval-rmse:0.175551\ttrain-rmspe:0.232682\teval-rmspe:0.198269\n",
      "[33]\ttrain-rmse:0.170419\teval-rmse:0.17318\ttrain-rmspe:0.230173\teval-rmspe:0.195716\n",
      "[34]\ttrain-rmse:0.168065\teval-rmse:0.170759\ttrain-rmspe:0.228255\teval-rmspe:0.19331\n",
      "[35]\ttrain-rmse:0.166345\teval-rmse:0.169158\ttrain-rmspe:0.226209\teval-rmspe:0.190586\n",
      "[36]\ttrain-rmse:0.165579\teval-rmse:0.168422\ttrain-rmspe:0.225115\teval-rmspe:0.187727\n",
      "[37]\ttrain-rmse:0.163458\teval-rmse:0.16627\ttrain-rmspe:0.223138\teval-rmspe:0.185094\n",
      "[38]\ttrain-rmse:0.161697\teval-rmse:0.164524\ttrain-rmspe:0.221459\teval-rmspe:0.183154\n",
      "[39]\ttrain-rmse:0.160797\teval-rmse:0.163703\ttrain-rmspe:0.220616\teval-rmspe:0.182293\n",
      "[40]\ttrain-rmse:0.160478\teval-rmse:0.163388\ttrain-rmspe:0.22032\teval-rmspe:0.181933\n",
      "[41]\ttrain-rmse:0.158728\teval-rmse:0.161866\ttrain-rmspe:0.218248\teval-rmspe:0.18007\n",
      "[42]\ttrain-rmse:0.15807\teval-rmse:0.161205\ttrain-rmspe:0.214659\teval-rmspe:0.178099\n",
      "[43]\ttrain-rmse:0.156524\teval-rmse:0.159612\ttrain-rmspe:0.205133\teval-rmspe:0.176178\n",
      "[44]\ttrain-rmse:0.155256\teval-rmse:0.158298\ttrain-rmspe:0.203892\teval-rmspe:0.17429\n",
      "[45]\ttrain-rmse:0.154076\teval-rmse:0.157329\ttrain-rmspe:0.202183\teval-rmspe:0.17328\n",
      "[46]\ttrain-rmse:0.152931\teval-rmse:0.156339\ttrain-rmspe:0.201114\teval-rmspe:0.172241\n",
      "[47]\ttrain-rmse:0.149805\teval-rmse:0.153029\ttrain-rmspe:0.198339\teval-rmspe:0.168741\n",
      "[48]\ttrain-rmse:0.149481\teval-rmse:0.15284\ttrain-rmspe:0.198761\teval-rmspe:0.168436\n",
      "[49]\ttrain-rmse:0.147832\teval-rmse:0.151157\ttrain-rmspe:0.196239\teval-rmspe:0.165688\n",
      "[50]\ttrain-rmse:0.146581\teval-rmse:0.14987\ttrain-rmspe:0.195027\teval-rmspe:0.164283\n",
      "[51]\ttrain-rmse:0.146211\teval-rmse:0.14954\ttrain-rmspe:0.194691\teval-rmspe:0.163912\n",
      "[52]\ttrain-rmse:0.14518\teval-rmse:0.148479\ttrain-rmspe:0.193117\teval-rmspe:0.162355\n",
      "[53]\ttrain-rmse:0.144394\teval-rmse:0.147745\ttrain-rmspe:0.192467\teval-rmspe:0.161581\n",
      "[54]\ttrain-rmse:0.144123\teval-rmse:0.147477\ttrain-rmspe:0.192568\teval-rmspe:0.161192\n",
      "[55]\ttrain-rmse:0.142484\teval-rmse:0.146058\ttrain-rmspe:0.189627\teval-rmspe:0.159497\n",
      "[56]\ttrain-rmse:0.141794\teval-rmse:0.145536\ttrain-rmspe:0.189076\teval-rmspe:0.158915\n",
      "[57]\ttrain-rmse:0.140879\teval-rmse:0.144481\ttrain-rmspe:0.188039\teval-rmspe:0.157964\n",
      "[58]\ttrain-rmse:0.13972\teval-rmse:0.143532\ttrain-rmspe:0.187086\teval-rmspe:0.15698\n",
      "[59]\ttrain-rmse:0.139475\teval-rmse:0.143259\ttrain-rmspe:0.186873\teval-rmspe:0.156713\n",
      "[60]\ttrain-rmse:0.13833\teval-rmse:0.142107\ttrain-rmspe:0.18588\teval-rmspe:0.155385\n",
      "[61]\ttrain-rmse:0.137608\teval-rmse:0.141498\ttrain-rmspe:0.18526\teval-rmspe:0.154716\n",
      "[62]\ttrain-rmse:0.13712\teval-rmse:0.141056\ttrain-rmspe:0.184451\teval-rmspe:0.154257\n",
      "[63]\ttrain-rmse:0.135712\teval-rmse:0.139601\ttrain-rmspe:0.182901\teval-rmspe:0.152401\n",
      "[64]\ttrain-rmse:0.135218\teval-rmse:0.139315\ttrain-rmspe:0.182918\teval-rmspe:0.151968\n",
      "[65]\ttrain-rmse:0.133899\teval-rmse:0.1383\ttrain-rmspe:0.172032\teval-rmspe:0.150677\n",
      "[66]\ttrain-rmse:0.132804\teval-rmse:0.137272\ttrain-rmspe:0.170677\teval-rmspe:0.14953\n",
      "[67]\ttrain-rmse:0.132395\teval-rmse:0.136879\ttrain-rmspe:0.170303\teval-rmspe:0.149111\n",
      "[68]\ttrain-rmse:0.132287\teval-rmse:0.13677\ttrain-rmspe:0.170179\teval-rmspe:0.148991\n",
      "[69]\ttrain-rmse:0.13196\teval-rmse:0.136513\ttrain-rmspe:0.169798\teval-rmspe:0.14856\n",
      "[70]\ttrain-rmse:0.131276\teval-rmse:0.135831\ttrain-rmspe:0.167971\teval-rmspe:0.147804\n",
      "[71]\ttrain-rmse:0.130727\teval-rmse:0.135454\ttrain-rmspe:0.167443\teval-rmspe:0.147335\n",
      "[72]\ttrain-rmse:0.130039\teval-rmse:0.1348\ttrain-rmspe:0.166819\teval-rmspe:0.146764\n",
      "[73]\ttrain-rmse:0.129348\teval-rmse:0.134184\ttrain-rmspe:0.16592\teval-rmspe:0.146013\n",
      "[74]\ttrain-rmse:0.128916\teval-rmse:0.133846\ttrain-rmspe:0.165549\teval-rmspe:0.145531\n",
      "[75]\ttrain-rmse:0.128605\teval-rmse:0.133624\ttrain-rmspe:0.165231\teval-rmspe:0.145348\n",
      "[76]\ttrain-rmse:0.128385\teval-rmse:0.133349\ttrain-rmspe:0.165013\teval-rmspe:0.144901\n",
      "[77]\ttrain-rmse:0.127708\teval-rmse:0.132737\ttrain-rmspe:0.164106\teval-rmspe:0.144001\n",
      "[78]\ttrain-rmse:0.127259\teval-rmse:0.132398\ttrain-rmspe:0.16327\teval-rmspe:0.143519\n",
      "[79]\ttrain-rmse:0.126815\teval-rmse:0.131937\ttrain-rmspe:0.162847\teval-rmspe:0.143035\n",
      "[80]\ttrain-rmse:0.126236\teval-rmse:0.131299\ttrain-rmspe:0.162371\teval-rmspe:0.142331\n",
      "[81]\ttrain-rmse:0.125998\teval-rmse:0.131104\ttrain-rmspe:0.16217\teval-rmspe:0.14215\n",
      "[82]\ttrain-rmse:0.125475\teval-rmse:0.130729\ttrain-rmspe:0.161618\teval-rmspe:0.141504\n",
      "[83]\ttrain-rmse:0.125249\teval-rmse:0.130556\ttrain-rmspe:0.161411\teval-rmspe:0.141359\n",
      "[84]\ttrain-rmse:0.124891\teval-rmse:0.130318\ttrain-rmspe:0.161054\teval-rmspe:0.141151\n",
      "[85]\ttrain-rmse:0.124229\teval-rmse:0.129867\ttrain-rmspe:0.160484\teval-rmspe:0.140594\n",
      "[86]\ttrain-rmse:0.123936\teval-rmse:0.12962\ttrain-rmspe:0.160153\teval-rmspe:0.140325\n",
      "[87]\ttrain-rmse:0.123566\teval-rmse:0.129239\ttrain-rmspe:0.159752\teval-rmspe:0.139826\n",
      "[88]\ttrain-rmse:0.123237\teval-rmse:0.128915\ttrain-rmspe:0.159211\teval-rmspe:0.139277\n",
      "[89]\ttrain-rmse:0.122822\teval-rmse:0.128589\ttrain-rmspe:0.157375\teval-rmspe:0.138981\n",
      "[90]\ttrain-rmse:0.122712\teval-rmse:0.128532\ttrain-rmspe:0.157279\teval-rmspe:0.138916\n",
      "[91]\ttrain-rmse:0.122441\teval-rmse:0.128313\ttrain-rmspe:0.156962\teval-rmspe:0.138673\n",
      "[92]\ttrain-rmse:0.122242\teval-rmse:0.128211\ttrain-rmspe:0.156762\teval-rmspe:0.138576\n",
      "[93]\ttrain-rmse:0.121989\teval-rmse:0.128105\ttrain-rmspe:0.156569\teval-rmspe:0.138491\n",
      "[94]\ttrain-rmse:0.121905\teval-rmse:0.128051\ttrain-rmspe:0.156498\teval-rmspe:0.138441\n",
      "[95]\ttrain-rmse:0.121674\teval-rmse:0.127898\ttrain-rmspe:0.156297\teval-rmspe:0.138288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96]\ttrain-rmse:0.121255\teval-rmse:0.127638\ttrain-rmspe:0.153014\teval-rmspe:0.137924\n",
      "[97]\ttrain-rmse:0.121186\teval-rmse:0.127589\ttrain-rmspe:0.152974\teval-rmspe:0.137868\n",
      "[98]\ttrain-rmse:0.120941\teval-rmse:0.127477\ttrain-rmspe:0.152702\teval-rmspe:0.137743\n",
      "[99]\ttrain-rmse:0.120562\teval-rmse:0.127117\ttrain-rmspe:0.152345\teval-rmspe:0.137328\n",
      "[100]\ttrain-rmse:0.120498\teval-rmse:0.127073\ttrain-rmspe:0.152284\teval-rmspe:0.137286\n",
      "[101]\ttrain-rmse:0.120138\teval-rmse:0.12685\ttrain-rmspe:0.151914\teval-rmspe:0.137037\n",
      "[102]\ttrain-rmse:0.119931\teval-rmse:0.126738\ttrain-rmspe:0.151665\teval-rmspe:0.136933\n",
      "[103]\ttrain-rmse:0.119766\teval-rmse:0.126654\ttrain-rmspe:0.151511\teval-rmspe:0.136853\n",
      "[104]\ttrain-rmse:0.119452\teval-rmse:0.126271\ttrain-rmspe:0.152852\teval-rmspe:0.136327\n",
      "[105]\ttrain-rmse:0.119157\teval-rmse:0.126095\ttrain-rmspe:0.152517\teval-rmspe:0.136077\n",
      "[106]\ttrain-rmse:0.118816\teval-rmse:0.12578\ttrain-rmspe:0.152169\teval-rmspe:0.135703\n",
      "[107]\ttrain-rmse:0.118586\teval-rmse:0.125647\ttrain-rmspe:0.150734\teval-rmspe:0.135527\n",
      "[108]\ttrain-rmse:0.11845\teval-rmse:0.12563\ttrain-rmspe:0.150612\teval-rmspe:0.135495\n",
      "[109]\ttrain-rmse:0.118257\teval-rmse:0.125561\ttrain-rmspe:0.150445\teval-rmspe:0.13541\n",
      "[110]\ttrain-rmse:0.118029\teval-rmse:0.125389\ttrain-rmspe:0.150158\teval-rmspe:0.135153\n",
      "[111]\ttrain-rmse:0.11779\teval-rmse:0.125184\ttrain-rmspe:0.149913\teval-rmspe:0.134786\n",
      "[112]\ttrain-rmse:0.117479\teval-rmse:0.12491\ttrain-rmspe:0.149504\teval-rmspe:0.134485\n",
      "[113]\ttrain-rmse:0.117073\teval-rmse:0.124725\ttrain-rmspe:0.149087\teval-rmspe:0.134315\n",
      "[114]\ttrain-rmse:0.116632\teval-rmse:0.124539\ttrain-rmspe:0.148726\teval-rmspe:0.134185\n",
      "[115]\ttrain-rmse:0.116478\teval-rmse:0.124489\ttrain-rmspe:0.148517\teval-rmspe:0.13414\n",
      "[116]\ttrain-rmse:0.116205\teval-rmse:0.124305\ttrain-rmspe:0.148245\teval-rmspe:0.133951\n",
      "[117]\ttrain-rmse:0.115451\teval-rmse:0.123708\ttrain-rmspe:0.146919\teval-rmspe:0.133182\n",
      "[118]\ttrain-rmse:0.115135\teval-rmse:0.123401\ttrain-rmspe:0.146922\teval-rmspe:0.132805\n",
      "[119]\ttrain-rmse:0.114782\teval-rmse:0.123142\ttrain-rmspe:0.146371\teval-rmspe:0.132452\n",
      "[120]\ttrain-rmse:0.114599\teval-rmse:0.123084\ttrain-rmspe:0.145992\teval-rmspe:0.132374\n",
      "[121]\ttrain-rmse:0.114467\teval-rmse:0.12306\ttrain-rmspe:0.145876\teval-rmspe:0.132339\n",
      "[122]\ttrain-rmse:0.114309\teval-rmse:0.123007\ttrain-rmspe:0.145708\teval-rmspe:0.132269\n",
      "[123]\ttrain-rmse:0.114119\teval-rmse:0.122831\ttrain-rmspe:0.14556\teval-rmspe:0.132069\n",
      "[124]\ttrain-rmse:0.113961\teval-rmse:0.122716\ttrain-rmspe:0.145399\teval-rmspe:0.131886\n",
      "[125]\ttrain-rmse:0.113756\teval-rmse:0.122488\ttrain-rmspe:0.145131\teval-rmspe:0.131276\n",
      "[126]\ttrain-rmse:0.113499\teval-rmse:0.122364\ttrain-rmspe:0.144892\teval-rmspe:0.13115\n",
      "[127]\ttrain-rmse:0.113314\teval-rmse:0.122254\ttrain-rmspe:0.144717\teval-rmspe:0.131069\n",
      "[128]\ttrain-rmse:0.113141\teval-rmse:0.122211\ttrain-rmspe:0.144524\teval-rmspe:0.131029\n",
      "[129]\ttrain-rmse:0.112839\teval-rmse:0.122065\ttrain-rmspe:0.144258\teval-rmspe:0.130879\n",
      "[130]\ttrain-rmse:0.112568\teval-rmse:0.121978\ttrain-rmspe:0.142978\teval-rmspe:0.130732\n",
      "[131]\ttrain-rmse:0.11241\teval-rmse:0.121922\ttrain-rmspe:0.142826\teval-rmspe:0.130702\n",
      "[132]\ttrain-rmse:0.112298\teval-rmse:0.121893\ttrain-rmspe:0.142658\teval-rmspe:0.130658\n",
      "[133]\ttrain-rmse:0.112058\teval-rmse:0.121759\ttrain-rmspe:0.14244\teval-rmspe:0.130518\n",
      "[134]\ttrain-rmse:0.111924\teval-rmse:0.121627\ttrain-rmspe:0.14158\teval-rmspe:0.130263\n",
      "[135]\ttrain-rmse:0.111738\teval-rmse:0.121486\ttrain-rmspe:0.141413\teval-rmspe:0.130107\n",
      "[136]\ttrain-rmse:0.111634\teval-rmse:0.121473\ttrain-rmspe:0.141321\teval-rmspe:0.1301\n",
      "[137]\ttrain-rmse:0.111133\teval-rmse:0.12101\ttrain-rmspe:0.140799\teval-rmspe:0.129548\n",
      "[138]\ttrain-rmse:0.111045\teval-rmse:0.121001\ttrain-rmspe:0.140717\teval-rmspe:0.129549\n",
      "[139]\ttrain-rmse:0.110788\teval-rmse:0.120953\ttrain-rmspe:0.138605\teval-rmspe:0.129459\n",
      "[140]\ttrain-rmse:0.110641\teval-rmse:0.120877\ttrain-rmspe:0.13785\teval-rmspe:0.129389\n",
      "[141]\ttrain-rmse:0.110522\teval-rmse:0.120834\ttrain-rmspe:0.137742\teval-rmspe:0.129341\n",
      "[142]\ttrain-rmse:0.110334\teval-rmse:0.120719\ttrain-rmspe:0.137574\teval-rmspe:0.129236\n",
      "[143]\ttrain-rmse:0.110193\teval-rmse:0.120645\ttrain-rmspe:0.137167\teval-rmspe:0.129155\n",
      "[144]\ttrain-rmse:0.11012\teval-rmse:0.120642\ttrain-rmspe:0.137105\teval-rmspe:0.129216\n",
      "[145]\ttrain-rmse:0.109918\teval-rmse:0.120576\ttrain-rmspe:0.136861\teval-rmspe:0.129138\n",
      "[146]\ttrain-rmse:0.109734\teval-rmse:0.120462\ttrain-rmspe:0.136329\teval-rmspe:0.129\n",
      "[147]\ttrain-rmse:0.109489\teval-rmse:0.120297\ttrain-rmspe:0.136097\teval-rmspe:0.128819\n",
      "[148]\ttrain-rmse:0.109339\teval-rmse:0.120228\ttrain-rmspe:0.135952\teval-rmspe:0.128749\n",
      "[149]\ttrain-rmse:0.109175\teval-rmse:0.120118\ttrain-rmspe:0.135788\teval-rmspe:0.128585\n",
      "[150]\ttrain-rmse:0.10891\teval-rmse:0.119952\ttrain-rmspe:0.135569\teval-rmspe:0.128433\n",
      "[151]\ttrain-rmse:0.108826\teval-rmse:0.119894\ttrain-rmspe:0.135492\teval-rmspe:0.128393\n",
      "[152]\ttrain-rmse:0.108642\teval-rmse:0.11976\ttrain-rmspe:0.135545\teval-rmspe:0.128212\n",
      "[153]\ttrain-rmse:0.108501\teval-rmse:0.119665\ttrain-rmspe:0.135364\teval-rmspe:0.128087\n",
      "[154]\ttrain-rmse:0.108333\teval-rmse:0.119568\ttrain-rmspe:0.135195\teval-rmspe:0.12799\n",
      "[155]\ttrain-rmse:0.108111\teval-rmse:0.119371\ttrain-rmspe:0.13498\teval-rmspe:0.127778\n",
      "[156]\ttrain-rmse:0.107905\teval-rmse:0.119246\ttrain-rmspe:0.134676\teval-rmspe:0.127682\n",
      "[157]\ttrain-rmse:0.107755\teval-rmse:0.119224\ttrain-rmspe:0.134527\teval-rmspe:0.127653\n",
      "[158]\ttrain-rmse:0.107517\teval-rmse:0.119165\ttrain-rmspe:0.134269\teval-rmspe:0.1276\n",
      "[159]\ttrain-rmse:0.107295\teval-rmse:0.119034\ttrain-rmspe:0.134049\teval-rmspe:0.127461\n",
      "[160]\ttrain-rmse:0.107078\teval-rmse:0.118861\ttrain-rmspe:0.133807\teval-rmspe:0.127257\n",
      "[161]\ttrain-rmse:0.106933\teval-rmse:0.118823\ttrain-rmspe:0.133726\teval-rmspe:0.12721\n",
      "[162]\ttrain-rmse:0.106785\teval-rmse:0.118823\ttrain-rmspe:0.13358\teval-rmspe:0.127234\n",
      "[163]\ttrain-rmse:0.106597\teval-rmse:0.118745\ttrain-rmspe:0.133341\teval-rmspe:0.127167\n",
      "[164]\ttrain-rmse:0.106425\teval-rmse:0.118625\ttrain-rmspe:0.133151\teval-rmspe:0.127048\n",
      "[165]\ttrain-rmse:0.106261\teval-rmse:0.118624\ttrain-rmspe:0.132912\teval-rmspe:0.127068\n",
      "[166]\ttrain-rmse:0.10605\teval-rmse:0.118521\ttrain-rmspe:0.132721\teval-rmspe:0.12693\n",
      "[167]\ttrain-rmse:0.10595\teval-rmse:0.11852\ttrain-rmspe:0.132626\teval-rmspe:0.126929\n",
      "[168]\ttrain-rmse:0.105796\teval-rmse:0.118452\ttrain-rmspe:0.13236\teval-rmspe:0.126816\n",
      "[169]\ttrain-rmse:0.10572\teval-rmse:0.1184\ttrain-rmspe:0.132271\teval-rmspe:0.126764\n",
      "[170]\ttrain-rmse:0.105481\teval-rmse:0.118299\ttrain-rmspe:0.13203\teval-rmspe:0.12667\n",
      "[171]\ttrain-rmse:0.105441\teval-rmse:0.118278\ttrain-rmspe:0.131991\teval-rmspe:0.126642\n",
      "[172]\ttrain-rmse:0.105325\teval-rmse:0.118243\ttrain-rmspe:0.131703\teval-rmspe:0.126615\n",
      "[173]\ttrain-rmse:0.105228\teval-rmse:0.118196\ttrain-rmspe:0.131627\teval-rmspe:0.126583\n",
      "[174]\ttrain-rmse:0.105084\teval-rmse:0.1181\ttrain-rmspe:0.131482\teval-rmspe:0.126467\n",
      "[175]\ttrain-rmse:0.104913\teval-rmse:0.118011\ttrain-rmspe:0.131311\teval-rmspe:0.126367\n",
      "[176]\ttrain-rmse:0.104743\teval-rmse:0.117877\ttrain-rmspe:0.131079\teval-rmspe:0.126242\n",
      "[177]\ttrain-rmse:0.104687\teval-rmse:0.117858\ttrain-rmspe:0.131026\teval-rmspe:0.126225\n",
      "[178]\ttrain-rmse:0.104595\teval-rmse:0.117809\ttrain-rmspe:0.123098\teval-rmspe:0.12618\n",
      "[179]\ttrain-rmse:0.104518\teval-rmse:0.117767\ttrain-rmspe:0.123027\teval-rmspe:0.126119\n",
      "[180]\ttrain-rmse:0.104314\teval-rmse:0.117649\ttrain-rmspe:0.122758\teval-rmspe:0.126023\n",
      "[181]\ttrain-rmse:0.104107\teval-rmse:0.117498\ttrain-rmspe:0.122483\teval-rmspe:0.125831\n",
      "[182]\ttrain-rmse:0.103999\teval-rmse:0.117414\ttrain-rmspe:0.122342\teval-rmspe:0.125725\n",
      "[183]\ttrain-rmse:0.103853\teval-rmse:0.117297\ttrain-rmspe:0.122191\teval-rmspe:0.125589\n",
      "[184]\ttrain-rmse:0.103734\teval-rmse:0.117224\ttrain-rmspe:0.122079\teval-rmspe:0.125517\n",
      "[185]\ttrain-rmse:0.10367\teval-rmse:0.117185\ttrain-rmspe:0.122006\teval-rmspe:0.125428\n",
      "[186]\ttrain-rmse:0.103593\teval-rmse:0.117177\ttrain-rmspe:0.121929\teval-rmspe:0.125414\n",
      "[187]\ttrain-rmse:0.1035\teval-rmse:0.11711\ttrain-rmspe:0.121813\teval-rmspe:0.125332\n",
      "[188]\ttrain-rmse:0.103335\teval-rmse:0.11707\ttrain-rmspe:0.121632\teval-rmspe:0.125235\n",
      "[189]\ttrain-rmse:0.103129\teval-rmse:0.116877\ttrain-rmspe:0.121368\teval-rmspe:0.125002\n",
      "[190]\ttrain-rmse:0.102878\teval-rmse:0.116675\ttrain-rmspe:0.121003\teval-rmspe:0.124703\n",
      "[191]\ttrain-rmse:0.102714\teval-rmse:0.116621\ttrain-rmspe:0.12084\teval-rmspe:0.124627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[192]\ttrain-rmse:0.102616\teval-rmse:0.116529\ttrain-rmspe:0.121199\teval-rmspe:0.124508\n",
      "[193]\ttrain-rmse:0.102481\teval-rmse:0.116448\ttrain-rmspe:0.121039\teval-rmspe:0.124367\n",
      "[194]\ttrain-rmse:0.10232\teval-rmse:0.116361\ttrain-rmspe:0.120846\teval-rmspe:0.124219\n",
      "[195]\ttrain-rmse:0.102192\teval-rmse:0.116311\ttrain-rmspe:0.120629\teval-rmspe:0.124159\n",
      "[196]\ttrain-rmse:0.102057\teval-rmse:0.116244\ttrain-rmspe:0.120522\teval-rmspe:0.124085\n",
      "[197]\ttrain-rmse:0.10187\teval-rmse:0.116113\ttrain-rmspe:0.12029\teval-rmspe:0.123842\n",
      "[198]\ttrain-rmse:0.101721\teval-rmse:0.116051\ttrain-rmspe:0.120133\teval-rmspe:0.123796\n",
      "[199]\ttrain-rmse:0.101579\teval-rmse:0.116034\ttrain-rmspe:0.119944\teval-rmspe:0.123758\n",
      "[200]\ttrain-rmse:0.101478\teval-rmse:0.115984\ttrain-rmspe:0.11984\teval-rmspe:0.123695\n",
      "[201]\ttrain-rmse:0.101339\teval-rmse:0.115964\ttrain-rmspe:0.119671\teval-rmspe:0.123669\n",
      "[202]\ttrain-rmse:0.101247\teval-rmse:0.115968\ttrain-rmspe:0.119562\teval-rmspe:0.123676\n",
      "[203]\ttrain-rmse:0.101176\teval-rmse:0.115949\ttrain-rmspe:0.11949\teval-rmspe:0.123643\n",
      "[204]\ttrain-rmse:0.10108\teval-rmse:0.115877\ttrain-rmspe:0.119367\teval-rmspe:0.123575\n",
      "[205]\ttrain-rmse:0.100932\teval-rmse:0.115867\ttrain-rmspe:0.119224\teval-rmspe:0.123564\n",
      "[206]\ttrain-rmse:0.100837\teval-rmse:0.115806\ttrain-rmspe:0.119133\teval-rmspe:0.123494\n",
      "[207]\ttrain-rmse:0.100745\teval-rmse:0.115766\ttrain-rmspe:0.119032\teval-rmspe:0.123453\n",
      "[208]\ttrain-rmse:0.100667\teval-rmse:0.115777\ttrain-rmspe:0.118955\teval-rmspe:0.123482\n",
      "[209]\ttrain-rmse:0.100489\teval-rmse:0.115725\ttrain-rmspe:0.118746\teval-rmspe:0.123402\n",
      "[210]\ttrain-rmse:0.100356\teval-rmse:0.115679\ttrain-rmspe:0.118616\teval-rmspe:0.123375\n",
      "[211]\ttrain-rmse:0.100267\teval-rmse:0.115647\ttrain-rmspe:0.118536\teval-rmspe:0.123338\n",
      "[212]\ttrain-rmse:0.100075\teval-rmse:0.115527\ttrain-rmspe:0.118329\teval-rmspe:0.123196\n",
      "[213]\ttrain-rmse:0.099931\teval-rmse:0.115431\ttrain-rmspe:0.118103\teval-rmspe:0.123032\n",
      "[214]\ttrain-rmse:0.09975\teval-rmse:0.115387\ttrain-rmspe:0.117896\teval-rmspe:0.123001\n",
      "[215]\ttrain-rmse:0.09959\teval-rmse:0.115296\ttrain-rmspe:0.117728\teval-rmspe:0.12295\n",
      "[216]\ttrain-rmse:0.099523\teval-rmse:0.115272\ttrain-rmspe:0.117668\teval-rmspe:0.122923\n",
      "[217]\ttrain-rmse:0.099371\teval-rmse:0.115254\ttrain-rmspe:0.117522\teval-rmspe:0.122916\n",
      "[218]\ttrain-rmse:0.099245\teval-rmse:0.115102\ttrain-rmspe:0.117416\teval-rmspe:0.12274\n",
      "[219]\ttrain-rmse:0.09919\teval-rmse:0.1151\ttrain-rmspe:0.117351\teval-rmspe:0.122744\n",
      "[220]\ttrain-rmse:0.099102\teval-rmse:0.115059\ttrain-rmspe:0.117268\teval-rmspe:0.122654\n",
      "[221]\ttrain-rmse:0.099007\teval-rmse:0.115007\ttrain-rmspe:0.117172\teval-rmspe:0.122572\n",
      "[222]\ttrain-rmse:0.098929\teval-rmse:0.114951\ttrain-rmspe:0.117057\teval-rmspe:0.122483\n",
      "[223]\ttrain-rmse:0.098831\teval-rmse:0.114929\ttrain-rmspe:0.116755\teval-rmspe:0.122473\n",
      "[224]\ttrain-rmse:0.098714\teval-rmse:0.114851\ttrain-rmspe:0.116625\teval-rmspe:0.122392\n",
      "[225]\ttrain-rmse:0.098595\teval-rmse:0.114831\ttrain-rmspe:0.116503\teval-rmspe:0.122377\n",
      "[226]\ttrain-rmse:0.09848\teval-rmse:0.114769\ttrain-rmspe:0.116383\teval-rmspe:0.1223\n",
      "[227]\ttrain-rmse:0.09836\teval-rmse:0.114739\ttrain-rmspe:0.116258\teval-rmspe:0.122267\n",
      "[228]\ttrain-rmse:0.098181\teval-rmse:0.114663\ttrain-rmspe:0.115931\teval-rmspe:0.122196\n",
      "[229]\ttrain-rmse:0.0981\teval-rmse:0.11461\ttrain-rmspe:0.11583\teval-rmspe:0.122122\n",
      "[230]\ttrain-rmse:0.098051\teval-rmse:0.114592\ttrain-rmspe:0.115795\teval-rmspe:0.122086\n",
      "[231]\ttrain-rmse:0.09799\teval-rmse:0.114631\ttrain-rmspe:0.115733\teval-rmspe:0.12215\n",
      "[232]\ttrain-rmse:0.097892\teval-rmse:0.114582\ttrain-rmspe:0.115619\teval-rmspe:0.12211\n",
      "[233]\ttrain-rmse:0.097813\teval-rmse:0.114539\ttrain-rmspe:0.115529\teval-rmspe:0.122065\n",
      "[234]\ttrain-rmse:0.0977\teval-rmse:0.114534\ttrain-rmspe:0.115412\teval-rmspe:0.122062\n",
      "[235]\ttrain-rmse:0.097602\teval-rmse:0.114495\ttrain-rmspe:0.115312\teval-rmspe:0.122007\n",
      "[236]\ttrain-rmse:0.097561\teval-rmse:0.114495\ttrain-rmspe:0.115266\teval-rmspe:0.122009\n",
      "[237]\ttrain-rmse:0.097326\teval-rmse:0.114397\ttrain-rmspe:0.115026\teval-rmspe:0.12191\n",
      "[238]\ttrain-rmse:0.097134\teval-rmse:0.114266\ttrain-rmspe:0.114835\teval-rmspe:0.121772\n",
      "[239]\ttrain-rmse:0.097028\teval-rmse:0.114216\ttrain-rmspe:0.114735\teval-rmspe:0.121738\n",
      "[240]\ttrain-rmse:0.096873\teval-rmse:0.114103\ttrain-rmspe:0.114575\teval-rmspe:0.121627\n",
      "[241]\ttrain-rmse:0.096785\teval-rmse:0.114111\ttrain-rmspe:0.114444\teval-rmspe:0.12165\n",
      "[242]\ttrain-rmse:0.096649\teval-rmse:0.114038\ttrain-rmspe:0.114272\teval-rmspe:0.12154\n",
      "[243]\ttrain-rmse:0.096464\teval-rmse:0.113996\ttrain-rmspe:0.114062\teval-rmspe:0.121421\n",
      "[244]\ttrain-rmse:0.096407\teval-rmse:0.11398\ttrain-rmspe:0.112982\teval-rmspe:0.12138\n",
      "[245]\ttrain-rmse:0.096253\teval-rmse:0.113909\ttrain-rmspe:0.112832\teval-rmspe:0.121258\n",
      "[246]\ttrain-rmse:0.096121\teval-rmse:0.113855\ttrain-rmspe:0.112695\teval-rmspe:0.121209\n",
      "[247]\ttrain-rmse:0.096033\teval-rmse:0.113819\ttrain-rmspe:0.112602\teval-rmspe:0.121157\n",
      "[248]\ttrain-rmse:0.095934\teval-rmse:0.113795\ttrain-rmspe:0.112502\teval-rmspe:0.121155\n",
      "[249]\ttrain-rmse:0.095811\teval-rmse:0.113763\ttrain-rmspe:0.112385\teval-rmspe:0.121108\n",
      "[250]\ttrain-rmse:0.09574\teval-rmse:0.113761\ttrain-rmspe:0.112319\teval-rmspe:0.121135\n",
      "[251]\ttrain-rmse:0.095669\teval-rmse:0.11374\ttrain-rmspe:0.112247\teval-rmspe:0.121125\n",
      "[252]\ttrain-rmse:0.095568\teval-rmse:0.113732\ttrain-rmspe:0.112121\teval-rmspe:0.121127\n",
      "[253]\ttrain-rmse:0.095434\teval-rmse:0.113671\ttrain-rmspe:0.111951\teval-rmspe:0.121043\n",
      "[254]\ttrain-rmse:0.095266\teval-rmse:0.113635\ttrain-rmspe:0.111502\teval-rmspe:0.121001\n",
      "[255]\ttrain-rmse:0.095159\teval-rmse:0.1136\ttrain-rmspe:0.111382\teval-rmspe:0.120936\n",
      "[256]\ttrain-rmse:0.094973\teval-rmse:0.113441\ttrain-rmspe:0.111591\teval-rmspe:0.120735\n",
      "[257]\ttrain-rmse:0.094781\teval-rmse:0.113384\ttrain-rmspe:0.111361\teval-rmspe:0.120672\n",
      "[258]\ttrain-rmse:0.094725\teval-rmse:0.11338\ttrain-rmspe:0.111299\teval-rmspe:0.120686\n",
      "[259]\ttrain-rmse:0.094592\teval-rmse:0.113317\ttrain-rmspe:0.111162\teval-rmspe:0.120623\n",
      "[260]\ttrain-rmse:0.094457\teval-rmse:0.11322\ttrain-rmspe:0.110031\teval-rmspe:0.120461\n",
      "[261]\ttrain-rmse:0.094404\teval-rmse:0.113196\ttrain-rmspe:0.109972\teval-rmspe:0.12042\n",
      "[262]\ttrain-rmse:0.094291\teval-rmse:0.113106\ttrain-rmspe:0.109826\teval-rmspe:0.120308\n",
      "[263]\ttrain-rmse:0.094135\teval-rmse:0.113019\ttrain-rmspe:0.109641\teval-rmspe:0.120214\n",
      "[264]\ttrain-rmse:0.094091\teval-rmse:0.113014\ttrain-rmspe:0.109818\teval-rmspe:0.120221\n",
      "[265]\ttrain-rmse:0.094022\teval-rmse:0.112986\ttrain-rmspe:0.109724\teval-rmspe:0.120186\n",
      "[266]\ttrain-rmse:0.093885\teval-rmse:0.112936\ttrain-rmspe:0.109556\teval-rmspe:0.120121\n",
      "[267]\ttrain-rmse:0.09382\teval-rmse:0.112907\ttrain-rmspe:0.109491\teval-rmspe:0.120091\n",
      "[268]\ttrain-rmse:0.093712\teval-rmse:0.112883\ttrain-rmspe:0.109373\teval-rmspe:0.120075\n",
      "[269]\ttrain-rmse:0.093632\teval-rmse:0.112826\ttrain-rmspe:0.109305\teval-rmspe:0.120032\n",
      "[270]\ttrain-rmse:0.093571\teval-rmse:0.112813\ttrain-rmspe:0.109247\teval-rmspe:0.11999\n",
      "[271]\ttrain-rmse:0.093417\teval-rmse:0.11277\ttrain-rmspe:0.108997\teval-rmspe:0.119949\n",
      "[272]\ttrain-rmse:0.093335\teval-rmse:0.112743\ttrain-rmspe:0.108912\teval-rmspe:0.119918\n",
      "[273]\ttrain-rmse:0.093232\teval-rmse:0.112702\ttrain-rmspe:0.108769\teval-rmspe:0.11987\n",
      "[274]\ttrain-rmse:0.093156\teval-rmse:0.112687\ttrain-rmspe:0.108679\teval-rmspe:0.119864\n",
      "[275]\ttrain-rmse:0.093099\teval-rmse:0.112663\ttrain-rmspe:0.108625\teval-rmspe:0.119808\n",
      "[276]\ttrain-rmse:0.092998\teval-rmse:0.112675\ttrain-rmspe:0.108529\teval-rmspe:0.119826\n",
      "[277]\ttrain-rmse:0.092898\teval-rmse:0.112598\ttrain-rmspe:0.108434\teval-rmspe:0.119747\n",
      "[278]\ttrain-rmse:0.092844\teval-rmse:0.112569\ttrain-rmspe:0.108377\teval-rmspe:0.119725\n",
      "[279]\ttrain-rmse:0.09271\teval-rmse:0.112567\ttrain-rmspe:0.108221\teval-rmspe:0.119718\n",
      "[280]\ttrain-rmse:0.092626\teval-rmse:0.112524\ttrain-rmspe:0.108149\teval-rmspe:0.119681\n",
      "[281]\ttrain-rmse:0.092555\teval-rmse:0.112516\ttrain-rmspe:0.108084\teval-rmspe:0.119679\n",
      "[282]\ttrain-rmse:0.09246\teval-rmse:0.112469\ttrain-rmspe:0.107701\teval-rmspe:0.119619\n",
      "[283]\ttrain-rmse:0.092392\teval-rmse:0.112447\ttrain-rmspe:0.10764\teval-rmspe:0.119587\n",
      "[284]\ttrain-rmse:0.092314\teval-rmse:0.112433\ttrain-rmspe:0.107572\teval-rmspe:0.119553\n",
      "[285]\ttrain-rmse:0.092214\teval-rmse:0.112399\ttrain-rmspe:0.107453\teval-rmspe:0.119553\n",
      "[286]\ttrain-rmse:0.092154\teval-rmse:0.112385\ttrain-rmspe:0.107355\teval-rmspe:0.119532\n",
      "[287]\ttrain-rmse:0.092044\teval-rmse:0.112377\ttrain-rmspe:0.107202\teval-rmspe:0.119518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[288]\ttrain-rmse:0.091914\teval-rmse:0.112312\ttrain-rmspe:0.106865\teval-rmspe:0.11948\n",
      "[289]\ttrain-rmse:0.091806\teval-rmse:0.112299\ttrain-rmspe:0.106758\teval-rmspe:0.119477\n",
      "[290]\ttrain-rmse:0.091722\teval-rmse:0.112322\ttrain-rmspe:0.106653\teval-rmspe:0.119487\n",
      "[291]\ttrain-rmse:0.091573\teval-rmse:0.112287\ttrain-rmspe:0.102885\teval-rmspe:0.11946\n",
      "[292]\ttrain-rmse:0.091515\teval-rmse:0.112271\ttrain-rmspe:0.102815\teval-rmspe:0.119436\n",
      "[293]\ttrain-rmse:0.091424\teval-rmse:0.11222\ttrain-rmspe:0.102681\teval-rmspe:0.119349\n",
      "[294]\ttrain-rmse:0.091336\teval-rmse:0.112189\ttrain-rmspe:0.102598\teval-rmspe:0.119269\n",
      "[295]\ttrain-rmse:0.091292\teval-rmse:0.112187\ttrain-rmspe:0.102556\teval-rmspe:0.119266\n",
      "[296]\ttrain-rmse:0.091127\teval-rmse:0.112125\ttrain-rmspe:0.102381\teval-rmspe:0.119171\n",
      "[297]\ttrain-rmse:0.091048\teval-rmse:0.112107\ttrain-rmspe:0.102306\teval-rmspe:0.119161\n",
      "[298]\ttrain-rmse:0.090958\teval-rmse:0.112064\ttrain-rmspe:0.102214\teval-rmspe:0.119118\n",
      "[299]\ttrain-rmse:0.090903\teval-rmse:0.112053\ttrain-rmspe:0.102165\teval-rmspe:0.119113\n",
      "[300]\ttrain-rmse:0.090838\teval-rmse:0.11205\ttrain-rmspe:0.102098\teval-rmspe:0.119116\n",
      "[301]\ttrain-rmse:0.090728\teval-rmse:0.112039\ttrain-rmspe:0.101964\teval-rmspe:0.119122\n",
      "[302]\ttrain-rmse:0.090653\teval-rmse:0.112037\ttrain-rmspe:0.101882\teval-rmspe:0.119123\n",
      "[303]\ttrain-rmse:0.090569\teval-rmse:0.111992\ttrain-rmspe:0.101796\teval-rmspe:0.119056\n",
      "[304]\ttrain-rmse:0.090464\teval-rmse:0.111954\ttrain-rmspe:0.101681\teval-rmspe:0.119039\n",
      "[305]\ttrain-rmse:0.090393\teval-rmse:0.111969\ttrain-rmspe:0.101602\teval-rmspe:0.119064\n",
      "[306]\ttrain-rmse:0.09031\teval-rmse:0.111976\ttrain-rmspe:0.101505\teval-rmspe:0.119074\n",
      "[307]\ttrain-rmse:0.090213\teval-rmse:0.111944\ttrain-rmspe:0.101396\teval-rmspe:0.119049\n",
      "[308]\ttrain-rmse:0.090146\teval-rmse:0.111941\ttrain-rmspe:0.101302\teval-rmspe:0.119044\n",
      "[309]\ttrain-rmse:0.090114\teval-rmse:0.111946\ttrain-rmspe:0.101274\teval-rmspe:0.119043\n",
      "[310]\ttrain-rmse:0.089914\teval-rmse:0.111801\ttrain-rmspe:0.100426\teval-rmspe:0.118876\n",
      "[311]\ttrain-rmse:0.089858\teval-rmse:0.111785\ttrain-rmspe:0.100357\teval-rmspe:0.118856\n",
      "[312]\ttrain-rmse:0.089759\teval-rmse:0.111769\ttrain-rmspe:0.100251\teval-rmspe:0.118856\n",
      "[313]\ttrain-rmse:0.08967\teval-rmse:0.111735\ttrain-rmspe:0.100131\teval-rmspe:0.118799\n",
      "[314]\ttrain-rmse:0.089601\teval-rmse:0.111727\ttrain-rmspe:0.10057\teval-rmspe:0.118769\n",
      "[315]\ttrain-rmse:0.089548\teval-rmse:0.111723\ttrain-rmspe:0.100507\teval-rmspe:0.118798\n",
      "[316]\ttrain-rmse:0.089458\teval-rmse:0.111744\ttrain-rmspe:0.100402\teval-rmspe:0.118839\n",
      "[317]\ttrain-rmse:0.089409\teval-rmse:0.111716\ttrain-rmspe:0.100357\teval-rmspe:0.118828\n",
      "[318]\ttrain-rmse:0.089348\teval-rmse:0.111723\ttrain-rmspe:0.100292\teval-rmspe:0.11884\n",
      "[319]\ttrain-rmse:0.089252\teval-rmse:0.11167\ttrain-rmspe:0.100186\teval-rmspe:0.118772\n",
      "[320]\ttrain-rmse:0.089146\teval-rmse:0.111602\ttrain-rmspe:0.100085\teval-rmspe:0.118712\n",
      "[321]\ttrain-rmse:0.089075\teval-rmse:0.111588\ttrain-rmspe:0.10001\teval-rmspe:0.118714\n",
      "[322]\ttrain-rmse:0.089038\teval-rmse:0.11158\ttrain-rmspe:0.098831\teval-rmspe:0.118722\n",
      "[323]\ttrain-rmse:0.088996\teval-rmse:0.111584\ttrain-rmspe:0.098786\teval-rmspe:0.118723\n",
      "[324]\ttrain-rmse:0.088918\teval-rmse:0.111517\ttrain-rmspe:0.098693\teval-rmspe:0.118666\n",
      "[325]\ttrain-rmse:0.08884\teval-rmse:0.111478\ttrain-rmspe:0.098605\teval-rmspe:0.118629\n",
      "[326]\ttrain-rmse:0.088777\teval-rmse:0.111477\ttrain-rmspe:0.098535\teval-rmspe:0.118621\n",
      "[327]\ttrain-rmse:0.088651\teval-rmse:0.111429\ttrain-rmspe:0.098399\teval-rmspe:0.118562\n",
      "[328]\ttrain-rmse:0.088582\teval-rmse:0.111374\ttrain-rmspe:0.098339\teval-rmspe:0.118511\n",
      "[329]\ttrain-rmse:0.08851\teval-rmse:0.111338\ttrain-rmspe:0.098271\teval-rmspe:0.118479\n",
      "[330]\ttrain-rmse:0.088401\teval-rmse:0.111355\ttrain-rmspe:0.098142\teval-rmspe:0.118473\n",
      "[331]\ttrain-rmse:0.088317\teval-rmse:0.111317\ttrain-rmspe:0.098058\teval-rmspe:0.118432\n",
      "[332]\ttrain-rmse:0.088249\teval-rmse:0.111314\ttrain-rmspe:0.09798\teval-rmspe:0.118434\n",
      "[333]\ttrain-rmse:0.088167\teval-rmse:0.11128\ttrain-rmspe:0.096833\teval-rmspe:0.1184\n",
      "[334]\ttrain-rmse:0.088068\teval-rmse:0.111278\ttrain-rmspe:0.096624\teval-rmspe:0.118409\n",
      "[335]\ttrain-rmse:0.087962\teval-rmse:0.111267\ttrain-rmspe:0.096457\teval-rmspe:0.118389\n",
      "[336]\ttrain-rmse:0.087922\teval-rmse:0.111257\ttrain-rmspe:0.096414\teval-rmspe:0.118369\n",
      "[337]\ttrain-rmse:0.087855\teval-rmse:0.111275\ttrain-rmspe:0.09632\teval-rmspe:0.118361\n",
      "[338]\ttrain-rmse:0.087809\teval-rmse:0.111276\ttrain-rmspe:0.096277\teval-rmspe:0.11838\n",
      "[339]\ttrain-rmse:0.087722\teval-rmse:0.111218\ttrain-rmspe:0.096163\teval-rmspe:0.118289\n",
      "[340]\ttrain-rmse:0.087648\teval-rmse:0.11122\ttrain-rmspe:0.096046\teval-rmspe:0.118296\n",
      "[341]\ttrain-rmse:0.087594\teval-rmse:0.111249\ttrain-rmspe:0.095991\teval-rmspe:0.118343\n",
      "[342]\ttrain-rmse:0.087498\teval-rmse:0.11122\ttrain-rmspe:0.095886\teval-rmspe:0.118313\n",
      "[343]\ttrain-rmse:0.087449\teval-rmse:0.111179\ttrain-rmspe:0.095837\teval-rmspe:0.118275\n",
      "[344]\ttrain-rmse:0.087415\teval-rmse:0.111204\ttrain-rmspe:0.095805\teval-rmspe:0.118304\n",
      "[345]\ttrain-rmse:0.087323\teval-rmse:0.111194\ttrain-rmspe:0.095687\teval-rmspe:0.118283\n",
      "[346]\ttrain-rmse:0.087265\teval-rmse:0.111211\ttrain-rmspe:0.095627\teval-rmspe:0.118306\n",
      "[347]\ttrain-rmse:0.087197\teval-rmse:0.111178\ttrain-rmspe:0.095548\teval-rmspe:0.118288\n",
      "[348]\ttrain-rmse:0.087129\teval-rmse:0.111178\ttrain-rmspe:0.095465\teval-rmspe:0.1183\n",
      "[349]\ttrain-rmse:0.08705\teval-rmse:0.11113\ttrain-rmspe:0.09538\teval-rmspe:0.118214\n",
      "[350]\ttrain-rmse:0.086958\teval-rmse:0.111121\ttrain-rmspe:0.095273\teval-rmspe:0.118203\n",
      "[351]\ttrain-rmse:0.086799\teval-rmse:0.111071\ttrain-rmspe:0.095063\teval-rmspe:0.118145\n",
      "[352]\ttrain-rmse:0.086739\teval-rmse:0.111051\ttrain-rmspe:0.094996\teval-rmspe:0.118123\n",
      "[353]\ttrain-rmse:0.08664\teval-rmse:0.110985\ttrain-rmspe:0.094879\teval-rmspe:0.118051\n",
      "[354]\ttrain-rmse:0.086533\teval-rmse:0.11096\ttrain-rmspe:0.094756\teval-rmspe:0.118026\n",
      "[355]\ttrain-rmse:0.086489\teval-rmse:0.110943\ttrain-rmspe:0.094738\teval-rmspe:0.118014\n",
      "[356]\ttrain-rmse:0.086447\teval-rmse:0.110947\ttrain-rmspe:0.094648\teval-rmspe:0.118019\n",
      "[357]\ttrain-rmse:0.086355\teval-rmse:0.110868\ttrain-rmspe:0.094557\teval-rmspe:0.117941\n",
      "[358]\ttrain-rmse:0.086307\teval-rmse:0.110844\ttrain-rmspe:0.09439\teval-rmspe:0.117898\n",
      "[359]\ttrain-rmse:0.086244\teval-rmse:0.110851\ttrain-rmspe:0.094292\teval-rmspe:0.117903\n",
      "[360]\ttrain-rmse:0.086203\teval-rmse:0.110833\ttrain-rmspe:0.094251\teval-rmspe:0.117882\n",
      "[361]\ttrain-rmse:0.086115\teval-rmse:0.110835\ttrain-rmspe:0.094144\teval-rmspe:0.11788\n",
      "[362]\ttrain-rmse:0.086024\teval-rmse:0.110828\ttrain-rmspe:0.094\teval-rmspe:0.117886\n",
      "[363]\ttrain-rmse:0.085967\teval-rmse:0.110765\ttrain-rmspe:0.093925\teval-rmspe:0.117808\n",
      "[364]\ttrain-rmse:0.085898\teval-rmse:0.11077\ttrain-rmspe:0.093855\teval-rmspe:0.117799\n",
      "[365]\ttrain-rmse:0.085789\teval-rmse:0.110774\ttrain-rmspe:0.093712\teval-rmspe:0.117823\n",
      "[366]\ttrain-rmse:0.085647\teval-rmse:0.110702\ttrain-rmspe:0.093557\teval-rmspe:0.117788\n",
      "[367]\ttrain-rmse:0.085526\teval-rmse:0.110568\ttrain-rmspe:0.093437\teval-rmspe:0.117621\n",
      "[368]\ttrain-rmse:0.085451\teval-rmse:0.110542\ttrain-rmspe:0.093355\teval-rmspe:0.117591\n",
      "[369]\ttrain-rmse:0.085432\teval-rmse:0.110544\ttrain-rmspe:0.093336\teval-rmspe:0.117592\n",
      "[370]\ttrain-rmse:0.085383\teval-rmse:0.11052\ttrain-rmspe:0.093275\teval-rmspe:0.117558\n",
      "[371]\ttrain-rmse:0.085249\teval-rmse:0.110444\ttrain-rmspe:0.093141\teval-rmspe:0.117463\n",
      "[372]\ttrain-rmse:0.085151\teval-rmse:0.110399\ttrain-rmspe:0.093032\teval-rmspe:0.117407\n",
      "[373]\ttrain-rmse:0.085077\teval-rmse:0.110362\ttrain-rmspe:0.092952\teval-rmspe:0.117366\n",
      "[374]\ttrain-rmse:0.085\teval-rmse:0.110369\ttrain-rmspe:0.09287\teval-rmspe:0.117385\n",
      "[375]\ttrain-rmse:0.08492\teval-rmse:0.110353\ttrain-rmspe:0.092748\teval-rmspe:0.11735\n",
      "[376]\ttrain-rmse:0.084854\teval-rmse:0.110334\ttrain-rmspe:0.092677\teval-rmspe:0.117333\n",
      "[377]\ttrain-rmse:0.084774\teval-rmse:0.110332\ttrain-rmspe:0.092557\teval-rmspe:0.117325\n",
      "[378]\ttrain-rmse:0.084691\teval-rmse:0.110319\ttrain-rmspe:0.092466\teval-rmspe:0.117317\n",
      "[379]\ttrain-rmse:0.084675\teval-rmse:0.11032\ttrain-rmspe:0.092448\teval-rmspe:0.117323\n",
      "[380]\ttrain-rmse:0.084582\teval-rmse:0.110227\ttrain-rmspe:0.092343\teval-rmspe:0.117128\n",
      "[381]\ttrain-rmse:0.084509\teval-rmse:0.110193\ttrain-rmspe:0.092259\teval-rmspe:0.117103\n",
      "[382]\ttrain-rmse:0.084413\teval-rmse:0.110138\ttrain-rmspe:0.092157\teval-rmspe:0.117031\n",
      "[383]\ttrain-rmse:0.084367\teval-rmse:0.110127\ttrain-rmspe:0.092097\teval-rmspe:0.117022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[384]\ttrain-rmse:0.084294\teval-rmse:0.110103\ttrain-rmspe:0.092014\teval-rmspe:0.11699\n",
      "[385]\ttrain-rmse:0.084225\teval-rmse:0.110091\ttrain-rmspe:0.091922\teval-rmspe:0.116971\n",
      "[386]\ttrain-rmse:0.084152\teval-rmse:0.110072\ttrain-rmspe:0.091838\teval-rmspe:0.116954\n",
      "[387]\ttrain-rmse:0.084039\teval-rmse:0.110058\ttrain-rmspe:0.0917\teval-rmspe:0.116916\n",
      "[388]\ttrain-rmse:0.083988\teval-rmse:0.110056\ttrain-rmspe:0.091645\teval-rmspe:0.116918\n",
      "[389]\ttrain-rmse:0.083942\teval-rmse:0.110042\ttrain-rmspe:0.091594\teval-rmspe:0.116903\n",
      "[390]\ttrain-rmse:0.083875\teval-rmse:0.110048\ttrain-rmspe:0.091504\teval-rmspe:0.116908\n",
      "[391]\ttrain-rmse:0.083818\teval-rmse:0.110018\ttrain-rmspe:0.091444\teval-rmspe:0.116871\n",
      "[392]\ttrain-rmse:0.08375\teval-rmse:0.11003\ttrain-rmspe:0.091371\teval-rmspe:0.116897\n",
      "[393]\ttrain-rmse:0.083678\teval-rmse:0.110025\ttrain-rmspe:0.090476\teval-rmspe:0.116892\n",
      "[394]\ttrain-rmse:0.083605\teval-rmse:0.110024\ttrain-rmspe:0.090392\teval-rmspe:0.116895\n",
      "[395]\ttrain-rmse:0.083516\teval-rmse:0.109984\ttrain-rmspe:0.090295\teval-rmspe:0.116879\n",
      "[396]\ttrain-rmse:0.08347\teval-rmse:0.109981\ttrain-rmspe:0.090237\teval-rmspe:0.11688\n",
      "[397]\ttrain-rmse:0.083401\teval-rmse:0.109971\ttrain-rmspe:0.090151\teval-rmspe:0.116861\n",
      "[398]\ttrain-rmse:0.083341\teval-rmse:0.109998\ttrain-rmspe:0.090085\teval-rmspe:0.116904\n",
      "[399]\ttrain-rmse:0.083284\teval-rmse:0.109976\ttrain-rmspe:0.090024\teval-rmspe:0.116878\n"
     ]
    }
   ],
   "source": [
    "print(\"Train a XGBoost model\")\n",
    "X_train, X_valid = train_test_split(train, test_size=0.012, random_state=10)\n",
    "y_train = np.log1p(X_train.Sales)\n",
    "y_valid = np.log1p(X_valid.Sales)\n",
    "dtrain = xgb.DMatrix(X_train[features], y_train)\n",
    "dvalid = xgb.DMatrix(X_valid[features], y_valid)\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, \\\n",
    "  early_stopping_rounds=100, feval=rmspe_xg, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating\n",
      "RMSPE: 0.116878\n"
     ]
    }
   ],
   "source": [
    "print(\"Validating\")\n",
    "yhat = gbm.predict(xgb.DMatrix(X_valid[features]))\n",
    "error = rmspe(X_valid.Sales.values, np.expm1(yhat))\n",
    "print('RMSPE: {:.6f}'.format(error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gbm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b16f23f2fc70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgbm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'gbm' is not defined"
     ]
    }
   ],
   "source": [
    "joblib.dump(gbm, 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[features].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[features].head().append(train[features].tail())\n",
    "#a.to_csv(\"test_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Make predictions on the test set\")\n",
    "dtest = xgb.DMatrix(test[features])\n",
    "#print(dtest)\n",
    "test_probs = gbm.predict(dtest)\n",
    "# Make Submission\n",
    "result = pd.DataFrame({\"Id\": test[\"Id\"],\"Date\":test[\"Date\"] ,'Sales': np.expm1(test_probs)})\n",
    "result.to_csv(\"xgboost_10_submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_feature_map(features)\n",
    "importance = gbm.get_fscore(fmap='xgb.fmap')\n",
    "importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "\n",
    "df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "df['fscore'] = df['fscore'] / df['fscore'].sum()\n",
    "\n",
    "featp = df.plot(kind='barh', x='feature', y='fscore', legend=True, figsize=(6, 10))\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.xlabel('relative importance')\n",
    "fig_featp = featp.get_figure()\n",
    "fig_featp.savefig('feature_importance_xgb.png', bbox_inches='tight', pad_inches=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################\n"
     ]
    }
   ],
   "source": [
    "print(\"#################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>Promo</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Year</th>\n",
       "      <th>WeekOfYear</th>\n",
       "      <th>CompetitionOpen</th>\n",
       "      <th>PromoOpen</th>\n",
       "      <th>IsPromoMonth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>2019</td>\n",
       "      <td>37</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  CompetitionDistance  Promo  SchoolHoliday  StoreType  Assortment  \\\n",
       "2      1               1270.0      1            0.0          3           1   \n",
       "\n",
       "   StateHoliday  DayOfWeek  Month  Day  Year  WeekOfYear  CompetitionOpen  \\\n",
       "2             0          6      9   15  2019          37            132.0   \n",
       "\n",
       "   PromoOpen  IsPromoMonth  \n",
       "2        0.0             0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=test[features]\n",
    "b=pd.DataFrame(a.iloc[2:3,])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1,1270,1,0,3,1,0,6,9,15,2019,37,132,0,0]]\n",
    "df = pd.DataFrame(data,columns=['Store','CompetitionDistance','Promo','SchoolHoliday','StoreType','Assortment',\n",
    "'StateHoliday','DayOfWeek','Month','Day','Year','WeekOfYear','CompetitionOpen','PromoOpen','IsPromoMonth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make predictions on the test set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4190.5186], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = joblib.load(\"model.pkl\")\n",
    "print(\"Make predictions on the test set\")\n",
    "#pr = pd.read_csv('test.csv')\n",
    "dtest =xgb.DMatrix(df)\n",
    "test_probs = model.predict(dtest)\n",
    "\n",
    "#result = pd.DataFrame({\"Id\": test[\"Id\"],\"Date\":test[\"Date\"] ,'Sales': np.expm1(test_probs)})\n",
    "#result.to_csv(\"pickel_model.csv\", index=False)\n",
    "result=test_probs\n",
    "np.expm1(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>Promo</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Year</th>\n",
       "      <th>WeekOfYear</th>\n",
       "      <th>CompetitionOpen</th>\n",
       "      <th>PromoOpen</th>\n",
       "      <th>IsPromoMonth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>2019</td>\n",
       "      <td>38</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>2019</td>\n",
       "      <td>37</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>2019</td>\n",
       "      <td>37</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2019</td>\n",
       "      <td>37</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "      <td>50</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "      <td>45</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "      <td>41</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "      <td>37</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "      <td>32</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  CompetitionDistance  Promo  SchoolHoliday  StoreType  Assortment  \\\n",
       "1      1               1270.0      1            0.0          3           1   \n",
       "2      1               1270.0      1            0.0          3           1   \n",
       "3      1               1270.0      1            0.0          3           1   \n",
       "4      1               1270.0      0            0.0          3           1   \n",
       "5      1               1270.0      0            0.0          3           1   \n",
       "6      1               1270.0      0            0.0          3           1   \n",
       "7      1               1270.0      0            0.0          3           1   \n",
       "8      1               1270.0      0            0.0          3           1   \n",
       "9      1               1270.0      0            0.0          3           1   \n",
       "\n",
       "   StateHoliday  DayOfWeek  Month  Day  Year  WeekOfYear  CompetitionOpen  \\\n",
       "1             0          0      9   16  2019          38            132.0   \n",
       "2             0          6      9   15  2019          37            132.0   \n",
       "3             0          5      9   14  2019          37            132.0   \n",
       "4             0          4      9   13  2019          37            132.0   \n",
       "5             0          0     12    9  2019          50            135.0   \n",
       "6             0          5     11    9  2019          45            134.0   \n",
       "7             0          2     10    9  2019          41            133.0   \n",
       "8             0          0      9    9  2019          37            132.0   \n",
       "9             0          4      8    9  2019          32            131.0   \n",
       "\n",
       "   PromoOpen  IsPromoMonth  \n",
       "1        0.0             0  \n",
       "2        0.0             0  \n",
       "3        0.0             0  \n",
       "4        0.0             0  \n",
       "5        0.0             0  \n",
       "6        0.0             0  \n",
       "7        0.0             0  \n",
       "8        0.0             0  \n",
       "9        0.0             0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[features].iloc[1:10,]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
